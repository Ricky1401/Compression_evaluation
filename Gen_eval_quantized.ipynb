{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf35815-3424-4e4d-be9c-b96d9bf5c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb60eb955c04ecfa3a739e671590f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda53e2dab1347b093dc2fd36d6fb04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322d1e615eec4f5b8bb442de70f175a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d5c25e58134ac2bd5f525cc038e653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d5e58c972b49c2a4ab2957db31f261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9686511252024775bc6354f37a170eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output', 'text'],\n",
      "    num_rows: 4430\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input', 'output', 'text'],\n",
      "    num_rows: 4430\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input', 'output', 'text'],\n",
      "    num_rows: 4430\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672da00266c34ac68e22ffd09309a5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "def load_io_dataset(split, uf=40):\n",
    "    data_files = []\n",
    "    data_files.append(f\"TTE_uf{uf}/TTE_with_IO_{split}.json\")\n",
    "    dataset = load_dataset(\"json\", data_files=f\"TTE_uf{uf}/TTE_with_IO_{split}.json\")\n",
    "\n",
    "    def format_example(example):\n",
    "        return {\n",
    "            \"text\": f\"Prompt: {example['input']}\\nResponse: {example['output']}\\n\"\n",
    "        }\n",
    "\n",
    "    dataset = dataset[\"train\"].map(format_example)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_io_dataset(\"train\")\n",
    "test_dataset = load_io_dataset(\"test\")\n",
    "eval_dataset = load_io_dataset(\"eval\")\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(eval_dataset)\n",
    "\n",
    "\n",
    "\n",
    "#model_name = \"./fine_tuned_qwen3-4b/checkpoint-277\"\n",
    "#model_name = \"./fine_tuned_adapters_qwen3-4b\"\n",
    "model_name = \"./LA-Framework/results/quantized_model/FT_Qwen3-4B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "\n",
    "inference_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"cuda\",\n",
    "    #torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_name = \"../Qwen/models--Qwen--Qwen3-4B/snapshots/1cfa9a7208912126459214e8b04321603b3df60c\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb358f2b-2f8f-4f99-8904-2e0378c7fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the user's watching history and the film's rating, order the 50 candidate films. Order the films where the first one of the list is the most likely to be watched by the user. The output should only contain the ordered list of the recommended films bounded by the  special strings '%% START RECOMMENDED LIST %%' and '%% END LIST %%'. Here follows the user's history and the list of candidate films.\n",
      "%% START HISTORY %%\n",
      "Movie name: Payback (1999)\tRating:3\n",
      "Movie name: Under Siege (1992)\tRating:3\n",
      "Movie name: Independence Day (ID4) (1996)\tRating:3\n",
      "Movie name: Double Jeopardy (1999)\tRating:3\n",
      "Movie name: Maverick (1994)\tRating:4\n",
      "Movie name: Man in the Iron Mask, The (1998)\tRating:3\n",
      "Movie name: Die Hard: With a Vengeance (1995)\tRating:3\n",
      "Movie name: Getaway, The (1994)\tRating:3\n",
      "Movie name: Demolition Man (1993)\tRating:3\n",
      "Movie name: Conspiracy Theory (1997)\tRating:3\n",
      "%% END HISTORY %%\n",
      "%% START CANDIDATES %%\n",
      "Movie name: Them! (1954)\n",
      "Movie name: Penitentiary II (1982)\n",
      "Movie name: Life and Times of Hank Greenberg, The (1998)\n",
      "Movie name: Omega Man, The (1971)\n",
      "Movie name: Bodyguard, The (1992)\n",
      "Movie name: Snake Eyes (1998)\n",
      "Movie name: Blowup (1966)\n",
      "Movie name: Doug's 1st Movie (1999)\n",
      "Movie name: Running Free (2000)\n",
      "Movie name: Free Enterprise (1998)\n",
      "Movie name: Run Lola Run (Lola rennt) (1998)\n",
      "Movie name: Broadway Damage (1997)\n",
      "Movie name: Midnight in the Garden of Good and Evil (1997)\n",
      "Movie name: Straight Story, The (1999)\n",
      "Movie name: Great Dictator, The (1940)\n",
      "Movie name: I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "Movie name: Ilsa, She Wolf of the SS (1974)\n",
      "Movie name: Master Ninja I (1984)\n",
      "Movie name: Dream for an Insomniac (1996)\n",
      "Movie name: Fluke (1995)\n",
      "Movie name: Isn't She Great? (2000)\n",
      "Movie name: For Whom the Bell Tolls (1943)\n",
      "Movie name: Limelight (1952)\n",
      "Movie name: Kidnapped (1960)\n",
      "Movie name: Greatest Show on Earth, The (1952)\n",
      "Movie name: Outbreak (1995)\n",
      "Movie name: Sixth Sense, The (1999)\n",
      "Movie name: Virtuosity (1995)\n",
      "Movie name: Cookie's Fortune (1999)\n",
      "Movie name: Richard III (1995)\n",
      "Movie name: Civil Action, A (1998)\n",
      "Movie name: Torso (Corpi Presentano Tracce di Violenza Carnale) (1973)\n",
      "Movie name: Tomb of Ligeia, The (1965)\n",
      "Movie name: Walk in the Sun, A (1945)\n",
      "Movie name: Wishmaster (1997)\n",
      "Movie name: Ring, The (1927)\n",
      "Movie name: Armageddon (1998)\n",
      "Movie name: Twister (1996)\n",
      "Movie name: Toxic Avenger Part III: The Last Temptation of Toxie, The (1989)\n",
      "Movie name: Alien: Resurrection (1997)\n",
      "Movie name: Guilty as Sin (1993)\n",
      "Movie name: Star Wars: Episode I - The Phantom Menace (1999)\n",
      "Movie name: Man of No Importance, A (1994)\n",
      "Movie name: Jackal, The (1997)\n",
      "Movie name: How to Make an American Quilt (1995)\n",
      "Movie name: Lethal Weapon 3 (1992)\n",
      "Movie name: Lost World: Jurassic Park, The (1997)\n",
      "Movie name: Bushwhacked (1995)\n",
      "Movie name: Muppets Take Manhattan, The (1984)\n",
      "Movie name: Last Night (1998)\n",
      "%% END CANDIDATES %%\n",
      "\n",
      "\n",
      "%% START RECOMMENDED LIST %%\n",
      "Movie name: Star Wars: Episode I - The Phantom Menace (1999)\n",
      "Movie name: Alien: Resurrection (1997)\n",
      "Movie name: Bodyguard, The (1992)\n",
      "Movie name: Snake Eyes (1998)\n",
      "Movie name: Outbreak (1995)\n",
      "Movie name: Lost World: Jurassic Park, The (1997)\n",
      "Movie name: Alien: Resurrection (1997)\n",
      "Movie name: Alien: Resurrection (1997)\n",
      "Movie name: Outbreak (1995)\n",
      "Movie name: Star Wars: Episode I - The Phantom Menace (1999)\n",
      "%% END LIST %% Based on the user's history and the candidate films, here is the ordered list of recommended films. The user has a history of watching action and sci-fi films with a moderate rating. They've watched several action movies like \"Independence Day\" and \"Die Hard: With a Vengeance,\" as well as some science fiction films like \"Bodyguard.\" The candidate list includes a mix of action, sci-fi, and some other genres. The recommended list prioritizes films that are similar to the user's history. The first film in the list, \"Star Wars: Episode I - The Phantom Menace (1999),\" is a sci-fi action film that aligns well with the user's preferences. \"Alien: Resurrection (1997)\" is another sci-fi action film that the user might enjoy. \"Bodyguard, The (1992)\" is a thriller that the user might find interesting given their history. \"Snake Eyes (1998)\" is an action film that's likely to be watched by the user. \"Outbreak (1995)\" is a thriller that combines action and suspense, making it a good recommendation. The rest of the list continues with films that are similar in genre and tone to the user's preferences.\n",
      "%% START RECOMMENDED LIST %%\n",
      "Movie name: Star Wars: Episode I - The Phantom Menace (1999)\n",
      "Movie name: Alien: Resurrection (1997)\n",
      "Movie name: Bodyguard, The (1992)\n",
      "Movie name: Snake Eyes (1998)\n",
      "Movie name: Outbreak (1995)\n",
      "%% END LIST %% Based on the user's history and the candidate films, here is the ordered list of recommended films. The user has watched several action and sci-fi films, and the recommended list includes films that are similar in genre and tone to the user's preferences. The first film in the list, \"Star Wars: Episode I - The Phantom Menace (1999),\" is a sci-fi action film that aligns well with the user's history. \"Alien: Resurrection (1997)\" is another sci-fi action film that the user might\n"
     ]
    }
   ],
   "source": [
    "prompt = eval_dataset[1]['input']\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = inference_model.generate(**inputs, max_new_tokens=600)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "818e31c0-d47b-471f-a111-c3719eaf659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm   # optional, for nicer progress\n",
    "\n",
    "\n",
    "def split_list(text, start_token, end_token):\n",
    "    phrase = text.split(start_token + \"\\n\")\n",
    "    movie_list = phrase[1].split(\"\\n\" + end_token)[0]\n",
    "    movie_list = movie_list.split(\"\\n\")\n",
    "    for i, movie in enumerate(movie_list):\n",
    "        movie_list[i] = movie.split(\"\\t\")\n",
    "    return movie_list\n",
    "\n",
    "\n",
    "def perform_and_return_comparison(sample):\n",
    "    #prompt = sample['text']\n",
    "    inputs = tokenizer(sample['input'], return_tensors=\"pt\").to(\"cuda\")\n",
    "    while True:\n",
    "        output = inference_model.generate(**inputs, max_new_tokens=600)\n",
    "        rating = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        if (\"%% START RECOMMENDED LIST %%\\n\" in rating):\n",
    "            break\n",
    "    \n",
    "    rating = split_list(rating, \"%% START RECOMMENDED LIST %%\", \"%% END LIST %%\")\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return {'input': sample['input'],\n",
    "            'rating': rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d854f-3d24-4d7f-aa68-0be1ca74e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####   Parallel evaluation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e856db00-d601-4283-aad1-75f00e1a260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3234cf1ae64a73a04433813cad2901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7d66404a0c4a72a15a6d1f37e6a06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19514488"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm   # optional, for nicer progress\n",
    "\n",
    "# Parallel LLM generation of evaluation's results\n",
    "\n",
    "def perform_and_return_comparison_batched(batch):\n",
    "    # batch is a dict with lists: {'input': [...], 'text': [...]}\n",
    "    inputs = tokenizer(\n",
    "        batch['input'],\n",
    "        return_tensors=\"pt\",padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024,  # ← set sensible value, e.g. 2048\n",
    "        padding_side='left'\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode():           # saves a bit of memory\n",
    "        outputs = inference_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=600\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.batch_decode(\n",
    "        outputs,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for i, rating_full in enumerate(decoded):\n",
    "        rating = split_list(\n",
    "            rating_full,\n",
    "            \"%% START RECOMMENDED LIST %%\",\n",
    "            \"%% END LIST %%\"\n",
    "        )\n",
    "        results.append({\n",
    "            'input': batch['input'][i],\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "    return {'results': results}   # list of dicts — datasets will flatten it\n",
    "\n",
    "# This is usually enough parallelism for one GPU\n",
    "eval_output = eval_dataset.map(\n",
    "    perform_and_return_comparison_batched,\n",
    "    batched=True,\n",
    "    batch_size=8,          # ← tune this: 4–16 most common sweet spot\n",
    "                           # larger = better GPU util, but risk of OOM\n",
    "    desc=\"Evaluating\",\n",
    "    remove_columns=eval_dataset.column_names,  # optional — keep only new fields\n",
    ")\n",
    "\n",
    "eval_output.to_json(\"peft_quantized_eval_processed_parallel.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.0 (Python 3.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
