{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d848eead-ba95-4aeb-a3f0-cb34119bcd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate>=0.26.0\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting transformers[torch]\n",
      "  Using cached transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.5)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-23.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.2)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Using cached huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers[torch])\n",
      "  Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typer-slim in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (0.12.5)\n",
      "Collecting safetensors>=0.4.3 (from transformers[torch])\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: torch>=2.4 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (2.7.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (5.9.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: shellingham in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (79.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4->transformers[torch]) (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer-slim->transformers[torch]) (8.1.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.4->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.4->transformers[torch]) (3.0.2)\n",
      "Using cached datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached peft-0.18.1-py3-none-any.whl (556 kB)\n",
      "Using cached bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl (60.7 MB)\n",
      "Using cached huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "Using cached multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Using cached pyarrow-23.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached transformers-5.2.0-py3-none-any.whl (10.4 MB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: xxhash, safetensors, pyarrow, multiprocess, hf-xet, huggingface-hub, tokenizers, datasets, bitsandbytes, accelerate, transformers, peft\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlflow 2.21.2 requires pyarrow<20,>=4.0.0, but you have pyarrow 23.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.2 datasets-4.5.0 hf-xet-1.2.0 huggingface-hub-1.4.1 multiprocess-0.70.18 peft-0.18.1 pyarrow-23.0.1 safetensors-0.7.0 tokenizers-0.22.2 transformers-5.2.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers[torch] 'accelerate>=0.26.0' peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db551b4-67b0-487f-acf8-c3e6d8171587",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_model = \"../CustomProtocol/LA-Framework-dist-peft/results/distilled-Qwen3-1.7B/bs16-lr1e-05-G4-N1-NN1-lm1-len384-lora-8-32-0.1/pe2_rs0.5_nr128_ln_sr_tm0.2/1773\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2689dea9-b0a5-4847-b883-22b42d42af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8d9df393df4ceda1eacb547526eede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf87e677876b4db1934139664408e956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fbe8306067419b9def098d0c71314b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d1dd9e047948b597dbf57ddb32cc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b13f1981274712982fe9ed6b6a895e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7ab47e3fb84a90812772a394bd01a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output', 'text'],\n",
      "    num_rows: 4430\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input', 'output', 'text'],\n",
      "    num_rows: 4430\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input', 'output', 'text'],\n",
      "    num_rows: 4430\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def load_io_dataset(split, uf_n=40):\n",
    "    data_files = []\n",
    "    data_files.append(f\"TTE_uf{uf_n}/TTE_with_IO_{split}.json\")\n",
    "    dataset = load_dataset(\"json\", data_files=f\"TTE_uf{uf_n}/TTE_with_IO_{split}.json\")\n",
    "\n",
    "    def format_example(example):\n",
    "        return {\n",
    "            \"text\": f\"Prompt: {example['input']}\\nResponse: {example['output']}\\n\"\n",
    "        }\n",
    "\n",
    "    dataset = dataset[\"train\"].map(format_example)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_io_dataset(\"train\")\n",
    "test_dataset = load_io_dataset(\"test\")\n",
    "eval_dataset = load_io_dataset(\"eval\")\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76886d4a-f06c-4a48-a54f-5a8163db1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e9256b6353483796d889fdd7c48a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(distilled_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    distilled_model,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfef83e9-2423-49c4-871a-f61a120bb9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the user's watching history and the film's rating, order the list of candidate films. Order the films where the first one of the list is the most likely to be watched by the user. The output should only contain the ordered list of the recommended films bounded by the  special strings '%% START RECOMMENDED LIST %%' and '%% END LIST %%'. Here follows the user's history and the list of candidate films.\n",
      "%% START HISTORY %%\n",
      "Movie name: Crocodile Dundee (1986)\tRating:4\n",
      "Movie name: Indiana Jones and the Temple of Doom (1984)\tRating:4\n",
      "Movie name: Ghost and the Darkness, The (1996)\tRating:4\n",
      "Movie name: Three Musketeers, The (1993)\tRating:4\n",
      "Movie name: Mission: Impossible (1996)\tRating:3\n",
      "Movie name: Golden Child, The (1986)\tRating:4\n",
      "Movie name: Monty Python and the Holy Grail (1974)\tRating:5\n",
      "Movie name: Toy Story 2 (1999)\tRating:3\n",
      "Movie name: Raising Arizona (1987)\tRating:4\n",
      "Movie name: Being John Malkovich (1999)\tRating:3\n",
      "%% END HISTORY %%\n",
      "%% START CANDIDATES %%\n",
      "Movie name: Sneakers (1992)\n",
      "Movie name: Patch Adams (1998)\n",
      "Movie name: Caligula (1980)\n",
      "Movie name: Eyes Wide Shut (1999)\n",
      "Movie name: Animal House (1978)\n",
      "Movie name: Happy Gilmore (1996)\n",
      "Movie name: Light Years (1988)\n",
      "Movie name: Marie Baie Des Anges (1997)\n",
      "Movie name: Carnosaur 2 (1995)\n",
      "Movie name: Sabotage (1936)\n",
      "Movie name: Rush Hour (1998)\n",
      "Movie name: Head On (1998)\n",
      "Movie name: Larger Than Life (1996)\n",
      "Movie name: King and I, The (1999)\n",
      "Movie name: Nightmare Before Christmas, The (1993)\n",
      "Movie name: I'll Never Forget What's 'is Name (1967)\n",
      "Movie name: Bamboozled (2000)\n",
      "Movie name: Bram Stoker's Dracula (1992)\n",
      "Movie name: House Arrest (1996)\n",
      "Movie name: In the Bleak Midwinter (1995)\n",
      "Movie name: Girl, Interrupted (1999)\n",
      "Movie name: Poison Ivy II (1995)\n",
      "Movie name: Close Encounters of the Third Kind (1977)\n",
      "Movie name: Transformers: The Movie, The (1986)\n",
      "Movie name: Private Benjamin (1980)\n",
      "Movie name: Little Mermaid, The (1989)\n",
      "Movie name: Central Station (Central do Brasil) (1998)\n",
      "Movie name: Hate (Haine, La) (1995)\n",
      "Movie name: Candleshoe (1977)\n",
      "Movie name: Nixon (1995)\n",
      "Movie name: Devil's Own, The (1997)\n",
      "Movie name: Whatever It Takes (2000)\n",
      "Movie name: Heartburn (1986)\n",
      "Movie name: Another Stakeout (1993)\n",
      "Movie name: Babyfever (1994)\n",
      "Movie name: Amityville: Dollhouse (1996)\n",
      "Movie name: Fish Called Wanda, A (1988)\n",
      "Movie name: Stand by Me (1986)\n",
      "Movie name: Puppet Master II (1990)\n",
      "Movie name: Naked Gun: From the Files of Police Squad!, The (1988)\n",
      "Movie name: Far From Home: The Adventures of Yellow Dog (1995)\n",
      "Movie name: Back to the Future (1985)\n",
      "Movie name: Living in Oblivion (1995)\n",
      "Movie name: Butch Cassidy and the Sundance Kid (1969)\n",
      "Movie name: Richard III (1995)\n",
      "Movie name: Caddyshack (1980)\n",
      "Movie name: Bug's Life, A (1998)\n",
      "Movie name: How to Make an American Quilt (1995)\n",
      "Movie name: Soft Fruit (1999)\n",
      "Movie name: Edge of Seventeen (1998)\n",
      "%% END CANDIDATES %%\n",
      "\n",
      "\n",
      "Based on the user's watching history and the film's rating, the ordered list of recommended films is as follows:\n",
      "%% START RECOMMENDED LIST %%\n",
      "Movie name: Monty Python and the Holy Grail (1974)\n",
      "Movie name: The Golden Child (1986)\n",
      "Movie name: Crocodile Dundee (1986)\n",
      "Movie name: Indiana Jones and the Temple of Doom (1984)\n",
      "Movie name: Ghost and the Darkness, The (1996)\n",
      "Movie name: Three Musketeers, The (1993)\n",
      "Movie name: Mission: Impossible (1996)\n",
      "Movie name: Golden Child, The (1986)\n",
      "Movie name: The Movie, Transformers (1986)\n",
      "Movie name: Patch Adams (1998)\n",
      "Movie name: Caligula (1980)\n",
      "Movie name: Eyes Wide Shut (1999)\n",
      "Movie name: Animal House (1978)\n",
      "Movie name: Happy Gilmore (1996)\n",
      "Movie name: Light Years (1988)\n",
      "Movie name: Marie Baie Des Anges (1997)\n",
      "Movie name: Carnosaur 2 (1995)\n",
      "Movie name: Sabotage (1936)\n",
      "Movie name: Rush Hour (1998)\n",
      "Movie name: Head On (1998)\n",
      "Movie name: Larger Than Life (1996)\n",
      "Movie name: King and I, The (1999)\n",
      "Movie name: Nightmare Before Christmas, The (1993)\n",
      "Movie name: I'll Never Forget What's 'is Name (1967)\n",
      "Movie name: Bamboozled (2000)\n",
      "Movie name: Bram Stoker's Dracula (1992)\n",
      "Movie name: House Arrest (1996)\n",
      "Movie name: In the Bleak Midwinter (1995)\n",
      "Movie name: Girl, Interrupted (1999)\n",
      "Movie name: Poison Ivy II (1995)\n",
      "Movie name: Close Encounters of the Third Kind (1977)\n",
      "Movie name: Transformers: The Movie, The (1986)\n",
      "Movie name: Private Benjamin (1980)\n",
      "Movie name: Little Mermaid, The (1989)\n",
      "Movie name: Central Station (Central do Brasil) (1998)\n",
      "Movie name: Hate (Haine, La) (1995)\n",
      "Movie name: Candleshoe (1977)\n",
      "Movie name: Nixon (1995)\n",
      "Movie name: Devil's Own, The (1997)\n",
      "Movie name: Whatever It Takes (2000)\n",
      "Movie name: Heartburn (1986)\n",
      "Movie name: Another Stakeout (1993)\n",
      "Movie name: Babyfever (1994)\n",
      "Movie name: Am\n"
     ]
    }
   ],
   "source": [
    "prompt = eval_dataset[2]['input']\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=600, min_new_tokens=100)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d021480a-883f-4a45-bdd8-d4aaef74dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm   # optional, for nicer progress\n",
    "\n",
    "inference_model = model\n",
    "\n",
    "def split_list(text, start_token, end_token):\n",
    "    if not (start_token + \"\\n\" in text):\n",
    "            return []\n",
    "    phrase = text.split(start_token + \"\\n\")\n",
    "    movie_list = phrase[1].split(\"\\n\" + end_token)[0]\n",
    "    movie_list = movie_list.split(\"\\n\")\n",
    "    for i, movie in enumerate(movie_list):\n",
    "        movie_list[i] = movie.split(\"\\t\")\n",
    "    return movie_list\n",
    "\n",
    "\n",
    "def perform_and_return_comparison(sample):\n",
    "    #prompt = sample['text']\n",
    "    inputs = tokenizer(sample['input'], return_tensors=\"pt\").to(\"cuda\")\n",
    "    while True:\n",
    "        output = inference_model.generate(**inputs, max_new_tokens=600)\n",
    "        rating = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        if (\"%% START RECOMMENDED LIST %%\\n\" in rating):\n",
    "            break\n",
    "    \n",
    "    rating = split_list(rating, \"%% START RECOMMENDED LIST %%\", \"%% END LIST %%\")\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return {'input': sample['input'],\n",
    "            'rating': rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214bab0-a3af-4738-86b3-7e7e74bde460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010fd469225446ffbad8102b56f296fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm   # optional, for nicer progress\n",
    "\n",
    "# Parallel LLM generation of evaluation's results\n",
    "\n",
    "def perform_and_return_comparison_batched(batch):\n",
    "    # batch is a dict with lists: {'input': [...], 'text': [...]}\n",
    "    inputs = tokenizer(\n",
    "        batch['input'],\n",
    "        return_tensors=\"pt\",padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024,  # ← set sensible value, e.g. 2048\n",
    "        padding_side='left'\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode():           # saves a bit of memory\n",
    "        outputs = inference_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=600\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.batch_decode(\n",
    "        outputs,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for i, rating_full in enumerate(decoded):\n",
    "        rating = split_list(\n",
    "            rating_full,\n",
    "            \"%% START RECOMMENDED LIST %%\",\n",
    "            \"%% END LIST %%\"\n",
    "        )\n",
    "        results.append({\n",
    "            'input': batch['input'][i],\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "    return {'results': results}   # list of dicts — datasets will flatten it\n",
    "\n",
    "# This is usually enough parallelism for one GPU\n",
    "eval_output = eval_dataset.map(\n",
    "    perform_and_return_comparison_batched,\n",
    "    batched=True,\n",
    "    batch_size=8,          # ← tune this: 4–16 most common sweet spot\n",
    "                           # larger = better GPU util, but risk of OOM\n",
    "    desc=\"Evaluating\",\n",
    "    remove_columns=eval_dataset.column_names,  # optional — keep only new fields\n",
    ")\n",
    "\n",
    "eval_output.to_json(\"peft_distilled_eval_processed_parallel.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.0 (Python 3.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
